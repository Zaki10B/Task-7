“AI doesn't have to be evil to destroy humanity – if AI has a goal and humanity just happens to be in the way, it will destroy humanity as a matter of 
course without even thinking about it, no hard feelings." – Elon Musk

AI (artificial intelligence) is the simulation of intelligence by machines. A key factor as part of human intelligence is self recognition and emotion, 
so whether AI is ever able to fully emulate human intelligence has a massive impact on that statement. I believe that Elon Musk is trying to allude to 
AI not feeling emotion or remorse for its action as he says “no hard feelings”, however, what the “goal” would be is unclear. If AI has no emotion then 
why would it have any goal other than to serve the task assigned by the programmer? So unless he means someone has tasked the AI with a goal which happens 
to also mean destroying humanity then the evil “blame” would fall upon the person who programmed the AI to achieve the “goal”.

In today's world there are already many positive examples of AI being implemented, and having a positive impact on the communities and environments it is 
in. For example, AI assistants in health care, Siri and Alexa, and in social media predicting what to show up in your feed. While all of these are positive,
there are still ethical issues they raise. For example, algorithmic bias has long been a topic of discussion which relates to AI. Algorithmic bias is a 
phenomenon that occurs when an algorithm produces results that are systematically prejudiced due to erroneous assumptions in the machine learning process. 
An example of this is amazon’s hiring AI which was biassed against women and was much more likely to hire a man than a woman for senior tech roles. 
However in this example, it can be argued that the AI did not know any better and therefore what it did was not “evil” it was simply completing the “goal”
by analysing previous data and therefore it was unaware what is was doing was wrong - because it lacked a key part of human intelligence - “thinking for 
itself”. This is a clear example of what Elon Musk was trying to say - it was just completing its goal oblivious to what else was going on. This strongly 
backs up Elon’s claim and provides a clear piece of evidence that what he is saying holds some truth.

However, despite Elon being a multi-billionaire generational mind, he has a history of saying things for his own benefit. For Example, recently he used 
his platform on twitter to announce he would be “buying Manchester United” after quickly claiming he was joking. But before this was tweeted this large 
amount of Manchester United stock (around 60,000) was bought which had been at a constant price, until he tweeted, sending the price up by over 17%! It is 
thought that it is possible that he bought the stock and did this to raise the price and make large amounts of money -  and he has a track record of doing 
similar pumping of crypto coins such as dogecoin. This shows that what he said may have just been for some ulterior motive he has, or a genuine fear of AI 
which can also cloud his judgement and cause him to state something that is not necessarily true. 

Overall, I believe that parts of Elon’s statement are true. I think that AI will complete an assigned task to the best of their ability, weather that 
means harming humans or not, and I also think that it wouldn’t make them evil as they are incapable of showing remorse and don't realise the consequences 
of their actions - they are just carrying out the job assigned. On the other hand, I do not believe that AI would have a goal that would involve the 
destruction of human kind on their own, unless it was given to them and therefore the programmer is the evil one to blame, however without enough evidence 
to come to a final conclusion, I believe that as AI continues to constantly learn more, and more and become better and better, time will tell the answer 
to Elon Musk’s question.
